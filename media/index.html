<!DOCTYPE html>
<html class="no-js" lang="en-US">

<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Partners</title>
  <link rel='dns-prefetch' href='http://s.w.org/' />
  <link rel='stylesheet' id='animate_css-css'  href='../wp-content/themes/twoears/bower_components/animate.css/animate.min.css%3Fver=4.6.1.css'
    type='text/css' media='all' />
  <link rel='stylesheet' id='theme_style-css'  href='../wp-content/themes/twoears/style.css%3Fver=3.1.0.css' type='text/css' media='all' />
  <!--[if lt IE 8]>
  <link rel='stylesheet' id='foundation_ie8_grid-css'  href='http://twoears.eu/wp-content/themes/cornerstone/css/ie8-grid-foundation-4.css?ver=1.0' type='text/css' media='all' />
  <![endif]-->
  <script type='text/javascript' src='../wp-content/themes/twoears/bower_components/foundation/js/vendor/modernizr.js%3Fver=2.7.1'></script>
  <script type='text/javascript' src='../wp-includes/js/jquery/jquery.js%3Fver=1.12.4'></script>
  <script type='text/javascript' src='../wp-includes/js/jquery/jquery-migrate.min.js%3Fver=1.4.1'></script>
  <link rel="canonical" href="http://twoears.eu" />
  <link rel='shortlink' href='http://twoears.eu' />
  <script type="text/javascript" src="../wp-content/plugins/wp-svg/data/svg.js" data-path="../wp-content/plugins/wp-svg/data/"></script>
  <link rel="shortcut icon" href="../wp-content/themes/twoears/img/favicon.png"/>
  <link href='../wp-content/themes/hagen/style.css' rel='stylesheet' />
  <!--[if lt IE 9]>
  <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.6.2/html5shiv.js"></script>
  <script src="//s3.amazonaws.com/nwapi/nwmatcher/nwmatcher-1.2.5-min.js"></script>
  <script src="//html5base.googlecode.com/svn-history/r38/trunk/js/selectivizr-1.0.3b.js"></script>
  <script src="//cdnjs.cloudflare.com/ajax/libs/respond.js/1.1.0/respond.min.js"></script>
  <![endif]-->
</head>


<body class="page page-id-16 page-parent page-template-default">
<div class="off-canvas-wrap">
    <div class="inner-wrap">


    <nav class="left-off-canvas-menu">
      <div>
        <ul class="nav-bar">
          <li class="page_item"><a href="../index.html">Home</a></li>
          <li class="page_item"><a href="../download/">Download</a></li>
          <li class="page_item"><a href="../project/">Project</a></li>
          <li class="page_item"><a href="../consortium/">Partners</a></li>
          <li class="page_item"><a href="../publications">Publications</a></li>
          <li class="page_item current_page_item active"><a href="../media/">Media</a></li>
          <li class="page_item"><a href="../events/">Events</a></li>
          <li class="page_item"><a href="../contacts">Contacts</a></li>
        </ul>
      </div>
    </nav>


        <header>
            <div class="logo">
                <a href="../index.html"><img src="../wp-content/themes/twoears/img/twoears-logo.png"
                                 width="360" height="460"/></a>
            </div>

            <div class="headlines">
                <div>
                    <h1>Media</h1>

                    <h2></h2>
                </div>
            </div>
        </header>
    <div class="container">
        
        <aside class="left">&nbsp;</aside>

        <main>
                            <article id="post-16" class="post-16 page type-page status-publish hentry">
                    <p>Here you can find publicly released multimedia contents, related to the project.<br />

<p>
<div id='insertPages_Content'><h1>Genomix Matlab Bridge in operation</h1></div><br />
<div id='insertPages_Content'><p>This video demonstrates the Genomix Matlab Bridge (GMB) developed in the project to connect the software architecture specific to robotics (see <a href="https://git.openrobots.org/projects/genom3" target="_blank">GenoM3</a>) with the Matlab platform. This enables real-time communication between the software components developed in Matlab (peripheral processors, cognitive processors) and those in the GenoM3 architecture (e.g., head/body movement, audiovisual signal acquisition). The clip shows a <a href="https://www.willowgarage.com/pages/pr2/overview" target="_blank">PR2</a> robot controlled in a simulated environment created with <a href="https://www.openrobots.org/morse/doc/latest/what_is_morse.html" target="_blank">MORSE</a>.</p>
<div style="width: 640px; " class="wp-video"><!--[if lt IE 9]><script>document.createElement('video');</script><![endif]-->
<video class="wp-video-shortcode" id="video-564-1" width="640" height="360" preload="metadata" controls="controls"><source type="video/mp4" src="../wp-content/uploads/2015/03/demo_morse_matlab_x264.mp4%3F_=1" /><a href="../wp-content/uploads/2015/03/demo_morse_matlab_x264.mp4">../wp-content/uploads/2015/03/demo_morse_matlab_x264.mp4</a></video></div>
</div></p>

<p>
<div id='insertPages_Content'>
  <h1><span style="font-variant:small-caps">Two!Ears</span> Sound Localisation Demo with KEMAR Dummy Head</h1></div><br />
<div id='insertPages_Content'><p>Here you can see the demonstration as posted below, but now connected with a KEMAR dummy head and torso simulator that rotates as seen in the GUI. This is made possible through the blackboard system (see the next demo below), the GenoM3 modules (for audio capturing via the KEMAR head and for its movement), and the Genomix MATLAB Bridge (GMB) that connects the two platforms.</p>
<p><iframe width="500" height="375" src="https://www.youtube.com/embed/flXSMy03pGg?feature=oembed" frameborder="0" allowfullscreen></iframe></p>
</div></p>

<p style="text-align: left;">
<div id='insertPages_Content'><h1><span style="font-variant:small-caps">Two!Ears</span> Sound Localisation Demo</h1></div></p>
<div id='insertPages_Content'><p>This is a demonstration of sound localisation for the project, using knowledge sources within a blackboard architecture. The knowledge sources cooperate to determine the position of each sound source, using information from internal auditory representations and head movements.</p>
<p><iframe width="500" height="375" src="https://www.youtube.com/embed/GWKDiyjfY-4?feature=oembed" frameborder="0" allowfullscreen></iframe></p>
</div>

<p style="text-align: left;"><a name="illustration-auditory-system"></a><br />
<div id='insertPages_Content'><h1>Illustration of the Human Auditory System</h1></div><br />
<div id='insertPages_Content'><p>If you want to talk about the auditory system to your students it is sometimes hard to find free material like illustrations of the phenomenon. Here, we provide an illustration that is available under the <a href="http://creativecommons.org/licenses/by/4.0/deed.en_US">Creative Commons license</a> and can be used for all purposes. The image is available as <a href="../wp-content/uploads/2014/02/auditory_perception.png">png</a>, <a href="../wp-content/uploads/2014/02/auditory_perception.svg">svg</a>, <a href="../wp-content/uploads/2014/02/auditory_perception.eps">eps</a>, <a href="../wp-content/uploads/2014/02/auditory_perception.pdf">pdf</a>.</p>
<p><a href="../wp-content/uploads/2014/02/auditory_perception.png"><img class="aligncenter size-medium wp-image-115" alt="auditory_perception" src="../wp-content/uploads/2014/02/auditory_perception.png" width="500" srcset="../wp-content/uploads/2014/02/auditory_perception.png 979w, ../wp-content/uploads/2014/02/auditory_perception-300x222.png 300w" sizes="(max-width: 979px) 100vw, 979px" /></a></p>
<p>The parts highlighted in blue are the auditory path way starting with the cochlea and ending in the auditory cortex.<br />
In between marks are highlighting the processing steps starting at the <em>cochlear nucleus</em>, <em>superior olivary complex</em>, and <em>lateral lemniscus</em> in the brainstem going further to the <em>inferior colliculus</em> in the midbrain and the <em>medial geniculate body</em> in the thalamus.</p>
<p>The idea for this illustration is borrowed from B. Grothe, M. Pecka, and D. McAlpine <em><a href="http://dx.doi.org/10.1152/physrev.00026.2009">Mechanisms of Sound Localization in Mammals</a></em>. The cochlea and outer ear is from L. Chittka and A. Brockmann, <em><a href="http://dx.doi.org/10.1371/journal.pbio.0030137">Perception space–the final frontier</a></em>. The sketch of the brain is based on K. Talbot et al, <em><a href="http://dx.doi.org/10.1371/journal.pone.0016886">Synaptic dysbindin-1 reductions in schizophrenia occur in an isoform-specific manner indicating their subsynaptic location</a></em>.</p>
</div></p>

<p>
<div id='insertPages_Content'><h1>Initial Press Release</h1></div><br />
<div id='insertPages_Content'><p><strong>How do humans listen?</strong><br />
<strong>Modelling auditory perception in the <span style="font-variant: small-caps;">Two!Ears</span> project</strong></p>
<p><a href="../wp-content/uploads/2014/02/kemar_headphones_rar_tub.jpg">
  <img class=" wp-image-131 alignright" src="../wp-content/uploads/2014/02/kemar_headphones_rar_tub.jpg" alt="kemar_headphones_rar_tub" width="300" height="225" /></a>
The goal of the <span style="font-variant: small-caps;">Two!Ears</span> project is to improve computer models of human hearing, and thereby advance our understanding of human auditory information processing. The project tackles this problem with a new approach: the human listener is seen as a multimodal agent who develops a world model through interactive listening and viewing. Coordinated by the TU Berlin, the international consortium has set the goal to develop an intelligent, active model of auditory perception and experience in the context of listening and viewing. The project received 3 million Euro funding from the European Commission.<br />
Up to now, computer models of human hearing have tended to focus on the evaluation of the signals received at the two ears – in other words, they are signal-driven. In the new <span style="font-variant: small-caps;">Two!Ears</span> approach, the prediction of human understanding and action will be improved by including hypothesis-driven processing. In such a scheme, world knowledge steers and improves the signal-driven evaluation. The system will be enabled to receive auditory events and integrate them with visual and proprioceptive information, for instance indications about the head orientation or the listener’s position in a room. It will thus attempt to describe an acoustic scene in the same way as a human listener does, in terms of primary perceptual constructs such as loudness, timbre and spatial extent. Additionally, the Two!Ears system will determine the meaning of the scene; for example, whether the perceived sounds come from a known or unknown speaker. The <span style="font-variant: small-caps;">Two!Ears</span> system will be realized on a robotic system which is capable of actively exploring its physical environment to orient itself and move around.<br />
The system is based on an open architecture which allows easy modification and extension. This is considered a crucial approach to enable widespread use within the scientific community of the auditory models and cognitive functions developed within the project. <span style="font-variant: small-caps;">Two!Ears</span> will have considerable impact on future developments in information and communication technologies where understanding and responding to sound is relevant. In addition, research in adjacent areas such as biology, medicine, perception and cognitive psychology will benefit from the outcomes of the project. As an example, hearing aid algorithms for listening in situations with many competing speakers might benefit from the insights of the project.<br />
The <span style="font-variant: small-caps;">Two!Ears</span> project started in December 2013 and has a funding period of three years. The international consortium comprises the following nine research institutes from the EU and the US: TU Berlin, Ruhr-University Bochum, TU Denmark, TU Eindhoven, Université Pierre et Marie Curie Paris, University Rostock, University of Sheffield, CNRS Toulouse, Rensselaer Polytechnic Institute Troy.</p>
</div></p>
                </article>
                    </main>

    </div>

    <footer class="row">
      <div class="row">
        <nav class="large-12 columns hide-for-small">
          <ul id="menu-primary-1" class="inline-list">
            <li id="menu-item-33" class="menu-item menu-item-type-post_type menu-item-object-page current-menu-item page_item page-item-2 menu-item-33"><a href="../index.html">Home</a></li>
            <li id="menu-item-624" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-624"><a href="../download/">Download</a></li>
            <li id="menu-item-35" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-has-children menu-item-35"><a href="../project/">Project</a></li>
            <li id="menu-item-39" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-39"><a href="../consortium/">Partners</a></li>
            <li id="menu-item-206" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-has-children menu-item-206"><a href="../publications">Publications</a></li>
            <li id="menu-item-41" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-has-children menu-item-41 current_page_item active"><a href="../media/">Media</a></li>
            <li id="menu-item-42" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-has-children menu-item-42"><a href="../events/">Events</a></li>
            <li id="menu-item-43" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-has-children menu-item-43"><a href="../contacts/">Contacts</a></li>
          </ul>
        </nav>
      </div>
      <a class="left-off-canvas-toggle menu-icon" ><span>Menu</span></a>
    </footer>

</div>
</div>
<link rel='stylesheet' id='mediaelement-css'  href='../wp-includes/js/mediaelement/mediaelementplayer.min.css%3Fver=2.22.0.css' type='text/css' media='all' />
<link rel='stylesheet' id='wp-mediaelement-css'  href='../wp-includes/js/mediaelement/wp-mediaelement.min.css%3Fver=4.6.1.css' type='text/css' media='all' />
<script type='text/javascript' src='../wp-content/themes/twoears/bower_components/foundation/js/foundation.min.js%3Fver=5.0.2'></script>
<script type='text/javascript' src='../wp-content/themes/twoears/bower_components/cheet.js/cheet.min.js%3Fver=0.2.3'></script>
<script type='text/javascript' src='../wp-content/themes/twoears/bower_components/Snap.svg/dist/snap.svg-min.js%3Fver=0.2.0'></script>
<script type='text/javascript' src='../wp-content/themes/twoears/bower_components/rem-unit-polyfill/js/rem.min.js%3Fver=1.1.0'></script>
<script type='text/javascript' src='../wp-content/themes/twoears/bower_components/buzz/dist/buzz.min.js%3Fver=1.1.0'></script>
<script type='text/javascript' src='../wp-content/themes/twoears/js/app.min.js%3Fver=1.0'></script>
<script type='text/javascript' src='../wp-includes/js/wp-embed.min.js%3Fver=4.6.1'></script>
<script type='text/javascript'>
/* <![CDATA[ */
var mejsL10n = {"language":"en-US","strings":{"Close":"Close","Fullscreen":"Fullscreen","Turn off Fullscreen":"Turn off Fullscreen","Go Fullscreen":"Go Fullscreen","Download File":"Download File","Download Video":"Download Video","Play":"Play","Pause":"Pause","Captions\/Subtitles":"Captions\/Subtitles","None":"None","Time Slider":"Time Slider","Skip back %1 seconds":"Skip back %1 seconds","Video Player":"Video Player","Audio Player":"Audio Player","Volume Slider":"Volume Slider","Mute Toggle":"Mute Toggle","Unmute":"Unmute","Mute":"Mute","Use Up\/Down Arrow keys to increase or decrease volume.":"Use Up\/Down Arrow keys to increase or decrease volume.","Use Left\/Right Arrow keys to advance one second, Up\/Down arrows to advance ten seconds.":"Use Left\/Right Arrow keys to advance one second, Up\/Down arrows to advance ten seconds."}};
var _wpmejsSettings = {"pluginPath":"\/wp-includes\/js\/mediaelement\/"};
/* ]]> */
</script>
<script type='text/javascript' src='../wp-includes/js/mediaelement/mediaelement-and-player.min.js%3Fver=2.22.0'></script>
<script type='text/javascript' src='../wp-includes/js/mediaelement/wp-mediaelement.min.js%3Fver=4.6.1'></script>
</body>
</html>
