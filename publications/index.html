<!DOCTYPE html>
<html class="no-js" lang="en-US">

<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Two!Ears - Publications</title>
  <link rel='dns-prefetch' href='http://s.w.org/' />
  <link rel='stylesheet' id='animate_css-css'  href='../wp-content/themes/twoears/bower_components/animate.css/animate.min.css%3Fver=4.6.1.css'
    type='text/css' media='all' />
  <link rel='stylesheet' id='theme_style-css'  href='../wp-content/themes/twoears/style.css%3Fver=3.1.0.css' type='text/css' media='all' />
  <!--[if lt IE 8]>
  <link rel='stylesheet' id='foundation_ie8_grid-css'  href='http://twoears.eu/wp-content/themes/cornerstone/css/ie8-grid-foundation-4.css?ver=1.0' type='text/css' media='all' />
  <![endif]-->
  <script type='text/javascript' src='../wp-content/themes/twoears/bower_components/foundation/js/vendor/modernizr.js%3Fver=2.7.1'></script>
  <script type='text/javascript' src='../wp-includes/js/jquery/jquery.js%3Fver=1.12.4'></script>
  <script type='text/javascript' src='../wp-includes/js/jquery/jquery-migrate.min.js%3Fver=1.4.1'></script>
  <link rel="canonical" href="http://twoears.eu" />
  <link rel='shortlink' href='http://twoears.eu' />
  <script type="text/javascript" src="../wp-content/plugins/wp-svg/data/svg.js" data-path="../wp-content/plugins/wp-svg/data/"></script>
  <link rel="shortcut icon" href="../wp-content/themes/twoears/img/favicon.png"/>
  <link href='../wp-content/themes/hagen/style.css' rel='stylesheet' />
  <!--[if lt IE 9]>
  <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.6.2/html5shiv.js"></script>
  <script src="//s3.amazonaws.com/nwapi/nwmatcher/nwmatcher-1.2.5-min.js"></script>
  <script src="//html5base.googlecode.com/svn-history/r38/trunk/js/selectivizr-1.0.3b.js"></script>
  <script src="//cdnjs.cloudflare.com/ajax/libs/respond.js/1.1.0/respond.min.js"></script>
  <![endif]-->
</head>


<body class="page page-id-205 page-parent page-template-default">
<div class="off-canvas-wrap">
    <div class="inner-wrap">


    <nav class="left-off-canvas-menu">
      <div>
        <ul class="nav-bar">
          <li class="page_item"><a href="../">Home</a></li>
          <li class="page_item"><a href="../download/">Download</a></li>
          <li class="page_item"><a href="../project/">Project</a></li>
          <li class="page_item"><a href="../consortium/">Partners</a></li>
          <li class="page_item current_page_item active"><a href="../publications">Publications</a></li>
          <li class="page_item"><a href="../media/">Media</a></li>
          <li class="page_item"><a href="../events/">Events</a></li>
          <li class="page_item"><a href="../contacts">Contacts</a></li>
        </ul>
      </div>
    </nav>

        <header>
            <div class="logo">
                <a href="../"><img src="../wp-content/themes/twoears/img/twoears-logo.png"
                                 width="360" height="460"/></a>
            </div>

            <div class="headlines">
                <div>
                    <h1>Publications</h1>

                    <h2></h2>
                </div>
            </div>
        </header>
    <div class="container">
        
        <aside class="left">&nbsp;</aside>

        <main>
                            <article id="post-205" class="post-205 page type-page status-publish hentry">
                    <p><a name="written-publications"></a><div id='insertPages_Content'><h2>Peer Reviewed Journals and Book chapters</h2>

<p>N. Ma, T. May and G. J. Brown &#8211;
Exploiting Deep Neural Networks and Head Movements for Robust Binaural Localisation of Multiple Sources in Reverberant Environments,
IEEE/ACM Transactions on Audio, Speech, and Language Processing, 25(12) pp. 2444-2453, 2017,
doi:<a target="_blank" href="https://doi.org/10.1109/TASLP.2017.2750760">10.1109/TASLP.2017.2750760</a></p>

<p>N. Desphande and J. Braasch &#8211;
Blind localization and segregation of two sources including a binaural head movement model,
Journal of the Acoustical Society of America, 142(1) EL113, 2017,
doi:<a target="_blank" href="https://doi.org/10.1121/1.4986800">10.1121/1.4986800</a></p>

<p>G. Bustamante, P. Danès, T. Forgue, A. Podlubne and J. Manhès &#8211;
An information based feedback control for audio-motor binaural localization,
Autonomous Robots, 2017,
doi:<a target="_blank" href="https://doi.org/10.1007/s10514-017-9639-8">10.1007/s10514-017-9639-8</a></p>

<p>I. Trowitzsch, J. Mohr, Y. Kashef and K.  Obermayer &#8211;
Robust Detection of Environmental Sounds in Binaural Auditory Scenes,
IEEE/ACM Transactions on Audio, Speech and Language Processing, 25(6) pp. 1344-1356, 2017,
doi:<a target="_blank" href="https://doi.org/10.1109/TASLP.2017.2690573">10.1109/TASLP.2017.2690573</a></p>

<p>H. Wierstorf, A.Raake and S. Spors &#8211;
Assessing localization accuracy in sound field synthesis,
Journal of the Acoustical Society of America, 141(2) pp. 1111-1119, 2017,
doi:<a target="_blank" href="https://doi.org/10.1121/1.4976061">10.1121/1.4976061</a></p>

<p>J. Braasch and J.  Blauert &#8211;
Auditory perception in rooms,
N. Xiang (ed). Architectural Acoustics Handbook, pp. 173–196, 2017</p>

<p>F. Winter, J. Ahrens and S. Spors &#8211;
On Analytic Methods for 2.5-D Local Sound Field Synthesis Using Circular Distributions of Secondary Sources,
IEEE/ACM Transactions on Audio, Speech, and Language Processing, 24(5) pp. 914-926, 2016,
doi:<a target="_blank" href="https://doi.org/10.1109/TASLP.2016.2531902">10.1109/TASLP.2016.2531902</a></p>

<p>H. Relaño-Iborraa,  T. May,  J. Zaar,  Ch. Scheidiger and  T. Dau &#8211;
Predicting speech intelligibility based on a correlation metric in the envelope power spectrum Domain,
Journal of the Acoustical Society of America, 140(4) pp. 2670-2679, 2016,
doi:<a target="_blank" href="https://doi.org/10.1121/1.4964505">10.1121/1.4964505</a></p>

<p>A. A. Kressnera and T. May,  Ch. J. Rozell &#8211;
Outcome measures based on classification performance fail to predict the intelligibility of binary-masked speech,
Journal of the Acoustical Society of America, 139(6) pp. 3033-3036, 2016,
doi:<a target="_blank" href="https://doi.org/10.1121/1.4952439">10.1121/1.4952439</a></p>

<p>U. Remesa, A. Ramírez Lópeza, L. Juvelaa, K. Palomäkia, G. J. Brown, P. Alkua and M. Kurimoa &#8211;
Comparing human and automatic speech recognition in a perceptual restoration Experiment,
Computer Speech and Language, 35 pp. 14-31, 2016,
doi:<a target="_blank" href="https://doi.org/10.1016/j.csl.2015.06.005">10.1016/j.csl.2015.06.005</a></p>

<p>J. Blauert and A. Raake &#8211;
Can current room-acoustics indices specify the quality of experience in concert halls?, Psychomusicology, music, mind, and brain, 25(3) pp. 253-255, 2015,
doi:<a target="_blank" href="http://dx.doi.org/10.1037/pmu0000074">10.1037/pmu0000074</a></p>

<p>S. Keronen, H. Kallasjoki, K. J. Palomäki, G. J. Brown and J. F. Gemmeke &#8211;
Feature enhancement of reverberant speech by distribution matching and non-negative matrix factorization,
EURASIP Journal on Advances in Signal Processing, pp. 76-86, 2015,
doi:<a target="_blank" href="https://doi.org/10.1186/s13634-015-0259-1">10.1186/s13634-015-0259-1</a></p>

<p>S. Argentiere, P. Danès, P. Souères &#8211;
A survey on sound source localization in robotics: From binaural to array processing methods,
Computer Speech and Language, 34(1) pp. 87-112, 2015,
doi:<a target="_blank" href="https://doi.org/10.1016/j.csl.2015.03.003">10.1016/j.csl.2015.03.003</a></p>

<p>R. Saeidi, R. Astudillo and D. Kolossa &#8211;
Uncertain LDA: Including Observation uncertainties in discriminative transforms,
IEEE Transactions on Pattern Analysis and Machine Intelligence, 38(7) pp. 1479-1488, 2015,
doi:<a target="_blank" href="https://doi.org/10.1109/TPAMI.2015.2481420">10.1109/TPAMI.2015.2481420</a></p>

<p>J. Blauert and A. Raake &#8211;
Komplexe instrumentelle Sound-Qualitätsbe-urteilung als Ausgangspunkt für Schätzungen des Kulturgrades der Rezipienten ‒ ein Versuch
(Complex instrumental judgements on sound quality as a starting point for estimations of the cultural Level),
Schmidt, W.G. (Ed.) Die Natur-Kultur-Grenze in Kunst und Wissenschaft, pp. 193‒214, 2014</p>

<p>T. May, T. Dau &#8211;
Computational speech segregation based on an auditory-inspired modulation analysis,
Journal of the Acoustical Society of America, 136(6) pp.3350-3359, 2014,
doi:<a target="_blank" href="https://doi.org/10.1121/1.4901711">10.1121/1.4901711</a></p>



<h2>Conference Proceedings and Presentations</h2>

<p>C. Schymura &#8211;
Monte Carlo Exploration for Active Binaural Localization,
IEEE Int. Conf. on Acoustics, Speech and Signal Processing (ICASSP), New Orleans, 2017</p>

<p>H. Meutzner &#8211;
Improving Audio-Visual Speech Recognition using Deep Neural Networks with Dynamic Stream Reliability Estimates,
IEEE Int. Conf. on Acoustics, Speech and Signal Processing (ICASSP), New Orleans, 2017</p>

<p>J. Blauert, Th. Walther &#8211;
Aufmerksam hören (Attentive listening),
German Annual Conference on Acoustics (DAGA), Kiel, 2017</p>

<p>C. Hold, L. Nagel, H. Wierstorf and A. Raake &#8211;
Positioning of Musical Foreground Parts in Surrounding Sound Stages,
AES Int. Conf. on Audio for Virtual and Augmented Reality, Los Angeles, 2016</p>

<p>A. Raake and H. Wierstorf &#8211;
Assessment of audio quality and experience using binaural-hearing models,
Proceedings of the 22nd International Congress on Acoustics (ICA), Buenos Aires, 2016</p>

<p>B. Cohen-Lhyver &#8211;
Multimodal fusion and inference using binaural audition and Vision,
Proceedings of the 22nd International Congress on Acoustics (ICA), Buenos Aires, 2016</p>

<p>J. Braasch, T. Pastore, N. Deshpande and J. Blauert &#8211;
A Precedence-effect model with top-down processing stages based on visual cues,
Proceedings of the 22nd International Congress on Acoustics (ICA), Buenos Aires, 2016</p>

<p>N. Deshpande and J. Braasch &#8211; Source-blind binaural source segregation utilizing head movement, Proceedings of the 22nd International Congress on Acoustics, (ICA), Buenos Aires, 2016</p>

<p>J. Braasch and N. Deshpande &#8211; A binaural model to segregate sound sources in the presence of early reflections using a multi-source precedence-effect model, Proceedings of the 22nd International Congress on Acoustics, (ICA), Buenos Aires, 2016</p>

<p>Th. Walther and J. Blauert &#8211; Simulating cognitive feedback in the context of binaural scene Analysis, Proceedings of the 22nd International Congress on Acoustics (ICA), Buenos Aires, 2016</p>

<p>J. Blauert &#8211; The advent of Communication Acoustics in retrospect, Proceedings of the 22nd International Congress on Acoustics (ICA), Buenos Aires, 2016</p>

<p>J. Käsbach, M. Hahmann, T. May and T.Dau &#8211; Assessing the contribution of binaural cues for apparent source width perception via a functional model, Proceedings of the 22nd International Congress on Acoustics (ICA), Buenos Aires, 2016</p>

<p>F. Winter and S. Spors &#8211; On Fractional Delay Interpolation for Local Wave Field Synthesis, European Signal Processing Conference (EURASIP), pp. 2415-2419, Budapest, 2016</p>

<p>N. Hahn and S. Spors &#8211; Comparison of Continuous Measurement Techniques for Spatial Room Impulse Responses, European Signal Processing Conference (EURASIP), pp. 1638-1642, Budapest, 2016<br />

G. Bustamante, P. Danès, T. Forgue and A. Podlubne &#8211; A One-step-ahead Information- based Feedback Control for Binaural Active Localization, European Signal Processing Conference (EURASIP), Budapest, 2016</p>

<p>N. Hahn, F. Winter and S. Spors &#8211; Local Wave Field Synthesis by Spatial Band-limitation in the Circular/Spherical Harmonics Domain, 140th AES Convention, Paris, 2016 </p>

<p>C. Hold. H. Wierstorf and A. Raake &#8211; The Difference Between Stereophony and Wave Field Synthesis in the Context of Popular Music, 140th AES Convention, Paris, 2016 </p>

<p>H. Wierstorf &#8211; Perceptual assessment of spatial sound: the Two!Ears Project, 140th AES Convention (invited talk), Paris, 2016 </p>

<p>F. Winter, H. Wierstorf, A. Podlubne, T. Forgue, J. Manhès, M. Herrb, S. Spors, A. Raake and P. Danès &#8211; Database of Binaural Room Impulse Responses of an Apartment-Like Environment, 140th AES Convention, Paris, 2016 </p>

<p>St. Zeiler, H. Meutzner, A. H. Abdelaziz and D. Kolossa &#8211; Introducing the Turbo-Twin-HMM for Audio-Visual Speech Enhancement, Proceedings of Interspeech, San Francisco, 2016</p>

<p>N. Ma and G.J. Brown &#8211; Speech localisation in a multitalker mixture by humans and machines, Proceedings of Interspeech, pp. 1149-1152, San Francisco, 2016</p>

<p>Y. Guo, X. Wang, C. Wu, Q. Fu, N. Ma and G.J. Brown &#8211; A robust dual-microphone speech source localization algorithm for reverberant Environments, Proceedings of Interspeech, pp. 1063-1066, San Francisco, 2016</p>

<p>Th. Bentsen, T. May, A. A. Kressner and T. Dau &#8211; Comparing the influence of spectro-temporal integration in computational speech Segregation, Proceedings of Interspeech, San Francisco, 2016</p>

<p>St. Zeiler, R. Nickel, N. Ma, G.J. Brown and D. Kolossa &#8211; Robust audiovisual speech recognition using noise-adaptive linear discriminant Analysis, IEEE Int. Conf. on Acoustics, Speech and Signal Processing (ICASSP), Shanghai, 2016</p>

<p>G. Bustamante, P. Danès, T. Forgue, A. Podlubne &#8211; Towards information-based feedback control for binaural active localization, IEEE Int. Conf. on Acoustics, Speech and Signal Processing (ICASSP), Shanghai, 2016</p>

<p>Th. Walther, J. Blauert and A. Raake &#8211; System zur Simulation von kognitivem Feedback im Kontext auditiver Szenenanalyse und auditiver Qualitätsbeurteilung (A system for the simulation of cognitive feedback in the context of auditory scene analysis and auditory sound-quality assessment), German Annual Conference on Acoustics (DAGA), Aachen, 2016</p>

<p>C. Hold, H. Wierstorf, A. Raake &#8211; Tonmischung für Stereophonie und Wellenfeldsynthese im Vergleich, German Annual Conference on Acoustics (DAGA), Aachen, 2016</p>

<p>C. Schymura, J. D. R. Grajales, D. Kolossa &#8211; Active localization of sound sources with binaural models, German Annual Conference on Acoustics (DAGA), Aachen, 2016</p>

<p>T. Walther, J. Blauert, A. Raake &#8211; System zur Simulation von kognitivem Feedback im Kontext auditiver Szene-<br />
nanalyse und auditiver Qualitätsbeurteilung, German Annual Conference on Acoustics (DAGA), Aachen, 2016</p>

<p>H. Wierstorf, A. Raake &#8211; Auf dem Weg zu binauraler Modellierung mit Kognition: das Two!Ears Modell, German Annual Conference on Acoustics (DAGA), Aachen, 2016</p>

<p>F. Winter, S. Spors &#8211; A comparison of sound field synthesis techniques for non-smooth secondary source distributions, German Annual Conference on Acoustics (DAGA), pp. 1463-1466, Aachen, 2016</p>

<p>N. Hahn and S. Sports &#8211; Analysis of time-varying system identification using the Normalized Least Mean Square algorithm in the context of data-based binaural Synthesis, German Annual Conference on Acoustics (DAGA), pp. 1012-1015, Aachen, 2016</p>

<p>B. Cohen-Lhyver &#8211; Modulating the Auditory Turn-to Reflex on the Basis of Multimodal Feedback Loops: the Dynamic Weighting Model, IEEE ROBIO, Zhuhai, 2015</p>

<p>F. Winter and S. Spors &#8211; Physical Properties of Local Wave Field Synthesis using Linear Loudspeaker Arrays, 138th Convention of the Audio Engineering Society, Warsaw, 2015</p>

<p>J. Blauert &#8211; Psychoakustik aus perzeptionistischer Sicht (Psychoacoustics from a perceptualist’s point of view), Proceedings 18th Annual German Society of Audiology Society (DGA) (invited plenary keynote lecture), 2015</p>

<p>J. Braasch, T. Pastore, N. Deshpande and J. Blauert &#8211; A bi-modal model to simulate auditory expectation for reverberation time and direct-to-reverberant energy from visual Feedback, 169th Meeting Acoustic Society of America (invited talk), Pittsburgh, 2015</p>

<p>N. Ma, R. Marxer, J. Barker and G. J. Brown &#8211; Exploiting synchrony spectra and deep neural networks for noise-robust automatic speech recognition, ASRU Workshop on the CHiME-3 Challenge, 2015</p>

<p>A. Raake, H. Wierstorf and J. Blauert &#8211; Audioqualitätsbeurteilung: Ein Fall für TWO!EARS &#8211; German Annual Conference on Acoustics (DAGA), Nuremberg, 2015</p>

<p>H. Wierstorf, Ch. Ende and A. Raake &#8211; Klangverfärbung in der Wellenfeldsynthese &#8211; Experimente und Modellierung, German Annual Conference on Acoustics (DAGA), Nuremberg, 2015</p>

<p>H. Wierstorf, C. Ende and A. Raake &#8211; Klangverfärbung in der Wellenfeldsynthese &#8211; Experimente und Modellierung, German Annual Conference on Acoustics (DAGA), Nuremberg, 2015</p>

<p>F. Winter and S. Spors &#8211; Parameter analysis for range extrapolation of head-related transfer functions using virtual local wave field synthesis, German Annual Conference on Acoustics (DAGA), Nuremberg, 2015</p>

<p>N. Hahn and S. Spors &#8211; Modal bandwidth reduction in data-based binaural synthesis including translatory head-movements,  German Annual Conference on Acoustics (DAGA), Nuremberg, 2015</p>

<p>E. Teret,  J. Braasch and  M. Torben Pastore &#8211; The influence of signal type on the internal auditory representation of a room, Journal of the Acoustical Society of America, 2015</p>

<p>F. Winter and S. Spors &#8211; Physical properties of local wave field synthesis using circular loudspeaker arrays, Proceedings of EuroNoise, Maastricht, 2015</p>

<p>N. Hahn and S. Spors &#8211; Sound field synthesis of virtual cylindrical waves using circular and spherical loudspeaker arrays, Proceedings of the 138th Convention of the Audio Engineering Society, 2015</p>

<p>F. Winter and S. Spors &#8211; Physical properties of local wave field sythesis using linear loudspeaker arrays, Proceedings of the 138th Convention of the Audio Engineering Society, 2015</p>

<p>V. Erbes, M. Geier, S. Weinzierl, and S. Spors &#8211; Database of single-channel and binaural room impulse responses of a 64-channel loudspeaker array, Proceedings of the 138th Convention of the Audio Engineering Society, 2015</p>

<p>N. Hahn and S. Spors &#8211; Continuous measurement of impulse responses on a circle using a uniformly moving microphone, European Signal Processing Conference,  2015</p>

<p>N. Ma, G.J. Brown and T. May &#8211; Robust localisation of multiple speakers exploiting deep neural networks and head movements, Proceedings of Interspeech, pp.3302–3306, Dresden, 2015</p>

<p>C. Schymura, F. Winter, D. Kolossa, S. Spors &#8211; Binaural Sound Source Localisation and Tracking using a Dynamic Spherical Head Model, Proceedings of Interspeech, Dresden, 2015</p>

<p>N. Ma, G. J. Brown and J. A. Gonzalez &#8211; Exploiting top-down Source Models to improve binaural Localisation of multiple Sources in reverberant Environments, Proceedings of Interspeech, Dresden, 2015</p>

<p>N. Ma, G.J. Brown and T. May  &#8211; Exploiting deep neural networks and head movements for binaural localisation of multiple speakers in reverberant conditions, Proceedings of Interspeech, Dresden, 2015</p>

<p>T. May, T. Bentsen and T. Dau &#8211; The role of temporal resolution in modulation based speech segregation, Proceedings of Interspeech, pp.170-174, Dresden, 2015</p>

<p>G. Bustamante, A. Portello, P. Danès &#8211; A Three-Stage Framework to Active Source Localization from a Binaural Head, IEEE Int. Conf. on Acoustics, Speech and Signal Processing (ICASSP), Invited Paper, Brisbane, Australia, 2015</p>

<p>T. May, N. Ma, G.J. Brown &#8211; Robust localisation of multiple speakers exploiting head movements and multi-conditional training of binaural cues, Proceedings of IEEE Int. Conf. on Acoustics, Speech and Signal Processing (ICASSP), pp.2679–2683, 2015</p>

<p>N. Ma, T. May, H. Wierstorf, G.J. Brown &#8211; A machine-hearing system exploiting head movements for binaural sound localisation in reverberant conditions, Proceedings of IEEE  Int. Conf. on Acoustics, Speech and Signal Processing (ICASSP), pp.2699–2703, 2015</p>

<p>G. Manfredi, M. Devy and D. Sidobre &#8211; Textured Object Recognition: Balancing Model Robustness and Complexity, 16th Int. Conf. on Computer Analysis of Images and Patterns (CAIP), 2015</p>

<p>A. Raake, H. Wierstorf and J. Blauert &#8211; A case for Two!Ears in audio-quality assessment, Proceedings of Forum Acusticum, Krakow, 2014 </p>

<p>J. Käsbach, T. May, G. Oskarsdottir, Ch.-H. Jeong and J. Chang &#8211; The effect of interaural-time-difference fluctuations on apparent source width, Proceedings of Forum Acusticum, Krakow, 2014 </p>

<p>F. Winter, F. Schultz, S. Spors &#8211; Localization Properties of Data-based Binaural Synthesis including Translatory Head-Movements, Forum Acusticum, Krakow, 2014 </p>

<p>H. Wierstorf, S. Spors &#8211; Predicting localization accuracy for stereophonic downmixes in Wave Field Synthesis, Forum Acusticum, Krakow, 2014 </p>

<p>T. Walther, B. Cohen-Lhyver &#8211; Multimodal feedback in auditory-based active scene Exploration, Forum Acousticum, Krakow, 2014 </p>

<p>C. Schymura, T. Walther, D. Kolossa, N. Ma, G.J. Brown &#8211; Binaural Sound Source Localisation using a Bayesian-network-based Blackboard System and Hypothesis-driven Feedback, Forum Acusticum, Krakow, 2014 </p>

<p>A. Raake, H. Wierstorf &#8211; A case for TWO!EARS in audio Quality assessment, Forum Acusticum, Krakow, 2014 </p>

<p>J. Blauert, D. Kolossa, P.Danès &#8211; Feedback Loops in Engineering Models of Binaural Listening, Proceedings of Meetings on Acoustics, 21(1), 2014</p>

<p>A. Raake, J. Blauert &#8211; Listening and Assessing with binaural models, EAA Joint Symposium on Auralization and Ambisonics, Berlin, 2014 </p>

<p>A. Raake et al. &#8211; Integral interactive model of auditory perception and experience, Jahrestagung der Deutschen Gesellschaft für Akustik, Oldenburg, 2014</p>

<p>T. May, T. Gerkmann &#8211; Generalization of supervised learning for binary mask estimation, IEEE IWAENC, pp. 154-158, Juan le pins, France, 2014</p>

<p>A. Portello, G. Bustamante, P. Danès, J. Piat, J. Manhès &#8211; Active Localization of an Intermittent Sound Source from a Moving Binaural Sensor, Forum Acusticum, Krakow, 2014</p>

<p>A. Portello, G. Bustamante, P. Danès, A. Mifsud &#8211; Localization of Multiple Sources from a Binaural Head in a Known Noisy Environment, IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Chicago, 2014</p>

<p>A. Raake, J. Blauert &#8211; Umfassende Modellierung der Vorgänge bei der Beurteilung von Sound-Qualität, 28. Tonmeistertagung, Cologne, 2014</p>



<h2>Public project deliverables</h2>
<p><a href="../wp-content/uploads/deliverables/D1.1_first_database_of_audio-visual_scenarios.pdf">D1.1 First Database of Audio-Visual Scenarios</a><br />
<a href="../wp-content/uploads/deliverables/D1.3_final_database_of_audio-visual_scenarios.pdf">D1.3 Final database of audio-visual Scenarios</a><br />
<a href="../wp-content/uploads/deliverables/D2.2_extension_of_the_monaural_model.pdf">D2.2 Extension of the monaural model (The Auditory Front-End Framework User Manual)</a><br />
<a href="../wp-content/uploads/deliverables/D2.3_extension_of_the_binaural_model_and_integration_of_monaural_and_binaural_models_in_software_package.pdf">D2.3 Extension of the binaural model (The Auditory Front-End Framework User Manual)</a><br />
<a href="../wp-content/uploads/deliverables/D2.4_extension_to_a_dynamic_binaural_model.pdf">D2.4 Extension to a dynamic binaural model (Evaluation and progress report)</a><br />
<a href="../wp-content/uploads/deliverables/D3.2_progress_report_on_software_architecture.pdf">D3.2 Progress report on software architecture</a><br />
<a href="../wp-content/uploads/deliverables/D3.3_implementation_of_software_architecture.pdf">D3.3 Implementation of software architecture</a><br />
<a href="../wp-content/uploads/deliverables/D3.4_progress_report_on_feature_selection_and_semantic_labelling.pdf">D3.4 Progress report on feature selection and semantic labelling</a><br />
<a href="../wp-content/uploads/deliverables/D3.5_evaluation_of_expert_system.pdf">D3.5 Report on evaluation of expert System</a><br />
<a href="../wp-content/uploads/deliverables/D4.3_final_integration_and_evaluation_report.pdf">D4.3 Final integration-&amp;-evaluation Report</a><br />
<a href="../wp-content/uploads/deliverables/D5.3_Final_Report_Robotics.pdf">D5.3 Final report on hardware/software integration &amp; robotics test bed</a><br />
<a href="../wp-content/uploads/deliverables/D6.1.3_software_for_analysis_of_dynamic_auditory_scenes.pdf">D6.1.3 Final report and evaluated software for analysis of dynamic auditory Scenes</a><br />
<a href="../wp-content/uploads/deliverables/D6.2.3_final_QoE_model_software.pdf">D6.2.3 QoE model software, final Version</a></p>


<h2>Related publications from other projects</h2>
<p>T. May, T. Dau &#8211; Requirements for the evaluation of computational speech segregation systems, Journal of the Acoustical Society of America, 136(6) EL398 2014,
doi:<a href="https://doi.org/10.1121/1.4901133">10.1121/1.4901133</a></p>
</div></p>
<p><a name="software-and-databases"></a><div id='insertPages_Content'><h2><span style="font-variant: small-caps;">Two!Ears</span> software components and databases</h2>
<p>Here we provide links to the collection of software modules and databases created by the <span style="font-variant: small-caps;">Two!Ears</span> consortium.</p>
<p>Main repository of the Two!Ears Auditory Model:<br />
<a href="https://github.com/TWOEARS/TwoEars" target="_blank"><i class="icon-laptop"></i> Two!Ears Auditory Model</a></p>
<p>Single software modules:<br />
<a href="https://github.com/TWOEARS/binaural-simulator" target="_blank"><i class="icon-laptop"></i> Two!Ears Binaural Simulator<br />
</a><a href="https://github.com/TWOEARS/auditory-front-end" target="_blank"><i class="icon-laptop"></i> Two!Ears Auditory Front End<br />
</a><a href="https://github.com/TWOEARS/blackboard-system" target="_blank"><i class="icon-laptop"></i> Two!Ears Blackboard System</a></p>
<p>Public available data from psychoacoustic experiments and acoustical measurements:<br />
<a href="https://dev.qu.tu-berlin.de/projects/twoears-database/repository" target="_blank"><i class="icon-laptop"></i> Two!Ears Database</a></p>


<h2>Other software components and databases</h2>
<p>In this section, links to additional databases and open source software collection are provided to which members of our consortium have contributed outside of the <span style="font-variant: small-caps;">Two!Ears</span> project.</p>
<p><a href="http://amtoolbox.sourceforge.net/" target="_blank"><i class="icon-laptop"></i> Auditory Modelling Toolbox</a><br />
<a href="https://github.com/sfstoolbox/sfs" target="_blank"><i class="icon-laptop"></i> Sound Field Synthesis Toolbox</a><br />
<a href="http://www.sofaconventions.org/" target="_blank"><i class="icon-laptop"></i> SOFA (Spatially Oriented Format for Acoustics)</a><br />
<a href="https://dev.qu.tu-berlin.de/projects/measurements/wiki/2010-11-kemar-anechoic" target="_blank"><i class="icon-microphone"></i> Head realted transfer functions (HRTFs) in the horizontal plane with a resolution of 1 degree</a></p>
</div></p>
                </article>
                    </main>

    </div>

    <footer class="row">
      <div class="row">
        <nav class="large-12 columns hide-for-small">
          <ul id="menu-primary-1" class="inline-list">
            <li id="menu-item-33" class="menu-item menu-item-type-post_type menu-item-object-page current-menu-item page_item page-item-2 menu-item-33"><a href="../">Home</a></li>
            <li id="menu-item-624" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-624"><a href="../download/">Download</a></li>
            <li id="menu-item-35" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-has-children menu-item-35"><a href="../project/">Project</a></li>
            <li id="menu-item-39" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-39"><a href="../consortium/">Partners</a></li>
            <li id="menu-item-206" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-has-children menu-item-206 current_page_item active"><a href="../publications">Publications</a></li>
            <li id="menu-item-41" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-has-children menu-item-41"><a href="../media/">Media</a></li>
            <li id="menu-item-42" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-has-children menu-item-42"><a href="../events/">Events</a></li>
            <li id="menu-item-43" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-has-children menu-item-43"><a href="../contacts/">Contacts</a></li>
          </ul>
        </nav>
      </div>
      <a class="left-off-canvas-toggle menu-icon" ><span>Menu</span></a>
    </footer>


</div>
</div>
<script type='text/javascript' src='../wp-content/themes/twoears/bower_components/foundation/js/foundation.min.js%3Fver=5.0.2'></script>
<script type='text/javascript' src='../wp-content/themes/twoears/bower_components/cheet.js/cheet.min.js%3Fver=0.2.3'></script>
<script type='text/javascript' src='../wp-content/themes/twoears/bower_components/Snap.svg/dist/snap.svg-min.js%3Fver=0.2.0'></script>
<script type='text/javascript' src='../wp-content/themes/twoears/bower_components/rem-unit-polyfill/js/rem.min.js%3Fver=1.1.0'></script>
<script type='text/javascript' src='../wp-content/themes/twoears/bower_components/buzz/dist/buzz.min.js%3Fver=1.1.0'></script>
<script type='text/javascript' src='../wp-content/themes/twoears/js/app.min.js%3Fver=1.0'></script>
<script type='text/javascript' src='../wp-includes/js/wp-embed.min.js%3Fver=4.6.1'></script>
</body>
</html>
